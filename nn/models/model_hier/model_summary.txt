Test_pig: 8
Epochs: 150
Batchsize: 32
Learningrate: 0.001
FactorDense: 3
Latent_dim = Num Paras: 43
Kernel: 5
Filter number Conv layer 1: 8
Filter number Conv layer 2: 8
Filter number Conv layer 3: 12
Activation function conv layer: elu
Activation function dense layer: elu
Activation function output layer: linear
bZeroPadding EIT signal: False
Resampling Parameters : False
Normalization strategy: block
Lossfunction: mae
sUseIndex: none
bWeightingLayer: False
bDropout layer: False
Dropout factor: 0.1
Batchnorm: True
HighpassEIT: False
LowpassEIT: False
useReziprok: none
normAorta: fixed
Reorder Mea: False
bMoreDense: False
bReorderParas: False
Change Time domain Stride pattern from 16 to: 16
Model Selection: ktpart43densehier



Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)               ┃ Output Shape           ┃       Param # ┃ Connected to            ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)   │ (None, 64, 1024, 1)    │             0 │ -                       │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ conv2d (Conv2D)            │ (None, 32, 256, 4)     │           164 │ input_layer[0][0]       │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ batch_normalization        │ (None, 32, 256, 4)     │            16 │ conv2d[0][0]            │
│ (BatchNormalization)       │                        │               │                         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ activation (Activation)    │ (None, 32, 256, 4)     │             0 │ batch_normalization[0]… │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dropout (Dropout)          │ (None, 32, 256, 4)     │             0 │ activation[0][0]        │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ conv2d_1 (Conv2D)          │ (None, 32, 128, 5)     │            65 │ dropout[0][0]           │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ batch_normalization_1      │ (None, 32, 128, 5)     │            20 │ conv2d_1[0][0]          │
│ (BatchNormalization)       │                        │               │                         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ activation_1 (Activation)  │ (None, 32, 128, 5)     │             0 │ batch_normalization_1[… │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dropout_1 (Dropout)        │ (None, 32, 128, 5)     │             0 │ activation_1[0][0]      │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ conv2d_2 (Conv2D)          │ (None, 11, 64, 7)      │           707 │ dropout_1[0][0]         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ batch_normalization_2      │ (None, 11, 64, 7)      │            28 │ conv2d_2[0][0]          │
│ (BatchNormalization)       │                        │               │                         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ activation_2 (Activation)  │ (None, 11, 64, 7)      │             0 │ batch_normalization_2[… │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dropout_2 (Dropout)        │ (None, 11, 64, 7)      │             0 │ activation_2[0][0]      │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ conv2d_3 (Conv2D)          │ (None, 4, 32, 9)       │         1,899 │ dropout_2[0][0]         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ batch_normalization_3      │ (None, 4, 32, 9)       │            36 │ conv2d_3[0][0]          │
│ (BatchNormalization)       │                        │               │                         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ activation_3 (Activation)  │ (None, 4, 32, 9)       │             0 │ batch_normalization_3[… │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dropout_3 (Dropout)        │ (None, 4, 32, 9)       │             0 │ activation_3[0][0]      │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ input_layer_1 (InputLayer) │ (None, 1)              │             0 │ -                       │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ flatten (Flatten)          │ (None, 1152)           │             0 │ dropout_3[0][0]         │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ concatenate (Concatenate)  │ (None, 1153)           │             0 │ input_layer_1[0][0],    │
│                            │                        │               │ flatten[0][0]           │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dense (Dense)              │ (None, 126)            │       145,404 │ concatenate[0][0]       │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dense_1 (Dense)            │ (None, 84)             │        10,668 │ dense[0][0]             │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dense_2 (Dense)            │ (None, 6)              │           510 │ dense_1[0][0]           │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ concatenate_1              │ (None, 90)             │             0 │ dense_2[0][0],          │
│ (Concatenate)              │                        │               │ dense_1[0][0]           │
├────────────────────────────┼────────────────────────┼───────────────┼─────────────────────────┤
│ dense_4 (Dense)            │ (None, 36)             │         3,276 │ concatenate_1[0][0]     │
└────────────────────────────┴────────────────────────┴───────────────┴─────────────────────────┘
 Total params: 488,281 (1.86 MB)
 Trainable params: 162,743 (635.71 KB)
 Non-trainable params: 50 (200.00 B)
 Optimizer params: 325,488 (1.24 MB)
